\documentclass{article}

\usepackage{ijcai13}
\usepackage{times}
\usepackage{amsmath} 
\usepackage{latexsym} 
\usepackage{ dsfont }
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{float}
\usepackage{circuitikz}
\usepackage{graphicx}
\usepackage[font=small]{subcaption}
\usepackage[font=small]{caption}
\usepackage{alltt}
\usepackage{dashrule}
\usepackage{array}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usetikzlibrary{arrows,automata, positioning, patterns,backgrounds}
\usetikzlibrary{arrows,shapes.gates.logic.US,shapes.gates.logic.IEC,calc}


\newtheorem{definition}{Definition}
\DeclareMathOperator*{\argmax}{arg\,max} 
\DeclareMathOperator*{\argmin}{arg\,min} 


\title{Bootstrap learning via modular concept discovery}

\author{Eyal Dechter \\
MIT\\
USA \\
edechter@mit.edu
\And
Jon Malmaud \\
MIT \\ 
USA \\
malmaud@mit.edu
\And 
Ryan P.  Adams \\
Harvard University\\
USA \\
rpa@seas.harvard.edu
\And
Joshua B. Tenenbaum \\
MIT\\
USA \\
jbt@mit.edu
}

\begin{document}

\maketitle

\begin{abstract}
 Suppose a learner is faced with a domain of problems about which it
 knows nearly nothing. It does not know the distribution of problems,
 the space of solutions is not smooth, and the reward signal is
 uninformative, providing perhaps a few bits of information but not
 enough to steer it effectively. How can such a learner ever get off
 the ground? A common intuition is that if the solutions to these
 problems share a common structure, and the learner can solve some
 simple problems by brute force, it should be able to extract useful
 components from these solutions and, by composing them, explore the
 solution space more efficiently. Here, we formalize this intuition,
 where the solution space is the space of typed functional programs
 and the gained information is stored as a stochastic grammar over
 programs. We propose an iterative procedure for exploring such
 spaces: in the first step of each iteration, the learner explores a
 finite subset of the domain, guided by a stochastic grammar; in the
 second step, the learner compresses the successful solutions from the
 first step to estimate a new stochastic grammar. We test this
 procedure on symbolic regression and boolean circuit learning and
 show that the learner discovers modular concepts for these
 domains. Whereas the learner is able to solve almost none of the
 posed problems in the procedure's first iteration, it rapidly becomes
 able to solve a large number by gaining abstract knowledge of the
 structure of the solution space.
 
 
\end{abstract}

\section{Introduction}
Many of the problems we want to solve in AI are best cast as search
problems. There are many search algorithms, but they typically exploit
local or topological structure in the search space. For example,
convex optimization and gradient based search methods take
advantage of local smoothness to move in good directions. Local search
algorithms move from one candidate solution to a neighboring
one. Heuristic search techniques take advantage of topological
structure to prune off large parts of the solution space.

However, many of the problems we want solve -- discovering scientific
theories, developing new technologies, figuring out how to bake -- do
not come with such a structured search space. This is particularly
true of problems, such as those mentioned, whose solutions can be
naturally framed as programs. Here we ask how to extract structure
from the space of programs by attempting to solve multiple related
problems in a given domain at once.

We take as inspiration the programmer who -- having reused several
subroutines to solve different but similar simple tasks -- creates a
function library to help manage the complexity of larger projects. The
EC algorithm, which we introduce here, builds a library of reusable
program components and places a distribution over these, effectively
learning from simple tasks a search space structure that enables it
to solve more complex tasks.

In this work, we try to see how far this idea of reusable function
definition can get us. We ask the following question: can an AI system
discover the structure latent in the solutions to multiple related
problems and thereby bootstrap effective exploration of the search
space? Can discovering modular program components transform a problem
from one in which search is intractable into a problem in which it
becomes increasingly feasible with experience?

Concretely, the EC algorithm works as follows. It begins with a small
library of program primitives and a distribution over programs
synthesized from this library. In each iteration, it generates
programs in order of highest probability according to the library
learned in the previous iteration. From the discovered solutions, it
finds new reusable functions that compress these solutions, and it
re-estimates the distribution over programs by weighting these new
functions according to their frequencies. In using compression as a
guide to the choice of representation, we instantiate the idea that
good representations are those which minimize the description length
of typical elements in the domain.

We show that this iterative approach allows us to achieve very high
performance in tasks where just searching according to the initial
distribution over program primitives clearly fails.


\section{Related Work}
The idea of discovering and using reusable subcomponents is an old one
in AI. Rendell's 1985 paper~\cite{DBLP:conf/ijcai/Rendell85},
``Substantial Constructive Induction Using Layered Information
Compression: Tractable Feature Formation in Search,'' presented within
a classical search paradigm the idea that compression provides a
heuristic for constructing good representations. Within the Inductive
Logic Programming (ILP) literature, researchers have explored ``Constructive
Induction,'' generating new and reusable logic programming
terms~\cite{DBLP:conf/ijcai/Muggleton87}. We apply these ideas to
learning functional programs, and believe that the modularity and
compositionality afforded by this representation is necessary for
these ideas to be successful.


Genetic programming
(GP)~\cite{DBLP:conf/foga/Koza92}~\cite{DBLP:conf/ices/KozaBAK96} has
tackled the problem of program learning and has explored the notion
that reusable functions are helpful. This work relies, however, on
stochastic local search over the space of programs, and automatically
discovering useful subroutines is seen as a helpful heuristic. More
recently, Liang et al.~\cite{liang10programs} used a stochastic
grammar over combinatory logic to induce shared structure in
multi-task program induction problems. We find this latter
representation compelling and use it here, but we see both this and
genetic programming as tackling the question of how to benefit from
shared structure in situations where local search might be successful
on its own. Such problems rely on domain knowledge -- whether in the
form of a fitness function or a likelihood function -- to provide
local structure to the search space.

But thes problems we want AI systems to solve often lack this kind of
built in structure. These are the kinds of problems more often
associated with ILP and classical AI than with GP and machine
learning. 
\\

%% AI and machine learning algorithms commonly take advantage of the
%% relationship between a performance metric (error, reward, fitness,
%% etc.) and the local or topological structure of the solution
%% space. Whether in discrete or continuous domains, the key is to design
%% such a relationship and write a algorithm that either moves in good
%% directions or prunes off large parts of the solution space. Whether or
%% not such a relationship exists depends on the representation, and much
%% work has gone into finding good representations for problem
%% solving. Recent work, especially in machine learning, has focused on
%% ``feature learning,'' with the explicit aim of discovered good
%% representational building blocks in vector-valued solutions spaces.

%% Many of the most natural solution representations for intelligent
%% agents, however, are not naturally expressed as vector-valued
%% spaces. Consider the problems of discovering scientific theories,
%% inventing new technologies, communicating with others, or executing a
%% complex motor routine (such as dancing or playing an instrument). The
%% solutions to these problems are most naturally expressed as programs,
%% that is, as the composition of modular components whose semantics are
%% determined by the actions of one component on another.

%% How can we learn good solution representations for these kinds of
%% tasks without building in the kind of domain knowledge that gives rise
%% to a useful relationship between representation and performance? How
%% can we get traction on a set of problems when small tweaks to
%% solutions give rise to wildly varying performances in an unpredictable
%% manner, or when, for most problems, most of the solutions fail in a
%% uniformly bad way? 

%% A popular idea is that good representations are those that encode the
%% data space in an efficient way, that is, that enable compression of
%% the data~\cite{}. For program representations, this most naturally
%% corresponds to defining reusable components so that the total number
%% of unique expressions for a set of solutions is minimized (i.e., this
%% is directly akin to the subroutine libraries programmers use to manage
%% the complexity of their code). 

%% In this work, we try to see how far reusable subroutine definition can
%% get us on its own. Our question is, Can discovering modular components
%% transform a problem from one in which brute-force search will not work
%% to a problem in which it does? 

%% To emphasize an impoverished relationship between reward signals and
%% program representations, we make our tasks all-or-none: a solution
%% either solves the problem or it does not, and partial solutions do not
%% get any credit. 

%% The intuitive approach to applying this idea is simple: if solutions
%% to problems in the domain share common structure, and there exist
%% problems whose solutions are simple enough to find by brute force,
%% then we should be able to extract a distribution over solution
%% subcomponents from these simple cases that allows us to run subsequent
%% searches more efficiently. 

%% More concretely, our algorithm works as follows: each iteration, it
%% first generates programs in order of highest probability according to
%% a subroutine distribution learned in the previous iteration. From the
%% discovered solutions, it finds new reusable subroutines that compress
%% these solutions and estimates their probabilities.

%% We show that this iterative approach allows us to achieve very high
%% performance in tasks where just searching according to the initial
%% distribution over program primitives clearly fails.



%%  \hline

%% AI and machine learning algorithms commonly take advantage of the idea
%% that local structure in the solution space is related to local
%% structure in the outcome. In continuous domains, learning algorithms
%% algorithms use error gradients to guide search. In discrete domains,
%% whether in heuristic or local search paradigms, knowledge about the
%% solution space topology and its relation to reward and cost metrics
%% enables pruning, reasoning, and moving in the solution space more
%% efficiently. However, choosing the representations that have
%% beneficial structural properties requires a lot of general and domain
%% knowledge, and this what researchers do and what they cannot leave up
%% to their algorithms.

%% What is a good strategy for an agent when its representation of the
%% solution space is not smooth with respect to the outcome? Many hard
%% learning problems have this property, especially those in which the
%% solution space is most naturally represented as a set of
%% programs. Consider the problems of discovering scientific theories,
%% inventing new technologies, learning to cook, or learning to
%% communicate. These are problems in which 1) solutions are best
%% described as programs (i.e. compositions of modular subroutines at
%% various levels of abstraction), 2) most of the solution space is bad
%% in a relatively uninformative way (i.e. it just doesn't work), and
%% thus 3) outcomes are not informative about how you are doing unless
%% you are already quite close to a solution.

%% Intuitively, the way to solve such problems is to find solutions to
%% simple cases in the domain and extract conceptual building blocks that
%% can be composed to scale up to complex cases. With experience, the
%% agent may be able to discover local structure in the solution space,
%% and utilize more traditional AI and machine learning techniques. In
%% this work, we will be focusing on the first phase of this learning
%% problem.

%% %% Of course, every learner 

%% %% Choosing the wrong representation, in
%% %% which local structure is not apparent, is often the difference between
%% %% a successful learner and an unsuccessful one. In many respects, this
%% %% may be the kind of situation that adult humans face when confronting
%% %% new domains: we have a lot of general knowledge of successful
%% %% representations, useful strategies, etc.

%% %% But suppose that you have very little knowledge of a domain. Your
%% %% intial representation of the domain is poor: ``nearby'' points in the
%% %% solutions space ellicit wildly different outcomes in unpredictable
%% %% ways. Or perhaps nearby points ellicit the same outcome and its not a
%% %% good one, so you don't know which way to go. Many learning problems,
%% %% especially those whose solutions are best described as programs, have
%% %% these qualities: imagine learning to synthesize new sentences





%% %% teness. We choose the representations our learners use
%% %% and these representations generally Imagine you are trying to learn to
%% %% bake via trial and error. You know what kind of ingredients are used
%% %% in baking (flour, water, butter, sugar, yeast, baking soda, etc.) and
%% %% you know a bit about how to combine these ingredient (mix, whisk,
%% %% etc.) and how to apply heat (oven). But baking is a notoriously
%% %% fragile process: ratios of ingredients, the order of mixing, cooking
%% %% temperatures, resting times, all make a huge difference, and the
%% %% outcome of the baking process is mostly all or none. Either the
%% %% outcome is what you expected or quite unlike it. Even if you do create
%% %% something similar to your intent, it is difficult to assign blame for
%% %% the outcome to any one step or decision along the way.

%% %% Many difficult learning problems have this structure -- learning
%% %% language, developing technologies and scientific theories, learning to
%% %% play instruments or execute other complex motor patterns. These are
%% %% problems in which 1) there is a large set of similar tasks; 2) their
%% %% solutions are best described as programs; 3) the solution space is
%% %% not smooth with respect to the outcome; 4) and the outcome is generally
%% %% uninformative unless you are already pretty close to a solution.

%% %% Of course, knowledge is not acquired wholly by trial and error. But in
%% %% many domains, there is at least initially such a period of ignorance,
%% %% and the question we are trying to tackle here is how you ever get off
%% %% the ground.


%% I need help here. 

%% %% Let a \emph{task} be a function $t : \mathcal{L} \rightarrow \{0,
%% %% 1\}$, where $\mathcal{L}$ is the set of all expressions in our
%% %% representation language. We say that $e \in \mathcal{L}$ \emph{solves}
%% %% task $t$ if $t(e) = 1$. Our goal is to solve as many tasks as
%% %% possible, as efficiently as possible. That is, suppose that there is a
%% %% distribution over tasks $t \sim  p_t(\cdot)$, we would like an ordering $O
%% %% = e_1, \dots $ on expressions in $\mathcal{L}$ such that if $p_t(t_1)
%% %% > p_t(t_2)$ then the first expression in $O$ to solve $t_1$ comes
%% %% before the first expression in $O$ to solve $t_2$.

%% %% We motivate a solution to this problem by considering a heirarchical
%% %% Bayesian formulation of the task distribution. Suppose we believe that
%% %% there is some underlying structure to $p_t(\cdot)$ that is explained by
%% %% the fact that for each task $t$ there is a latent expressions $e \in
%% %% \mathcal{L}$ drawn from a stochastic grammar $\mathcal{G}$ and that 

%% %% \begin{align}
%% %% e &\sim p_\mathcal{L}(\cdot) = \mathcal{G}\\
%% %% t | e &\sim \text{U}\{ \text{tasks solved by }e\}.
%% %% \end{align}

%% %% Then $p_t(t) = \sum_{e_j \in \mathcal{L} \text{ s.t. } t(e_j) = 1}
%% %% p_\mathcal{L}(e_j)$. If we make the assumption that for the set $E$ of
%% %% expressions in this sum, there is some expression $e^*$ such that
%% %% $p_\mathcal{L}(e^*) >> p_\mathcal{L}(e), e \neq e^*$, then we have, approximately, 
%% %% \[ p_t(t) \propto} p_\mathcal{L}(e^*). \] 

%% %% This suggests a way to find the ordering $O$: infer a stochastic
%% %% grammar $G$, under the assumption that $G$ favors one solution to a
%% %% given task over any other, and order the elements of $\mathcal{L}$
%% %% according to $G$.

%% %% Thus, our basic procedure will be to search for a single ``good''
%% %% solution for as many tasks as we can, and to use those solutions to
%% %% estimate a stochastic grammar. Our search will be performed in the
%% %% order of the most recently inferred grammar. So as our ordering
%% %% becomes more efficient and we can solve more tasks, we learn better
%% %% stochastic grammars.

%% %% Formally then, our goal is to solve the following minimal feedback
%% %% multi-task program induction problem: suppose we are given set of
%% %% \emph{tasks} $T=\{t_k\}_{k=1}^K$ where each task is a function $t_i :
%% %% \mathcal{L} \rightarrow \{0, 1\}$, where $\mathcal{L}$ is the set of
%% %% programs in our language.  We say that $ p \in \mathcal{L}$
%% %% \emph{solves} $t_i$ if $ t_i(p) = 1$. Our goal is to find a set of
%% %% solutions $X = \{x_k\}_{k=1}^k \subset \mathcal{L}$ such that

%% %% \[
%% %% X = \argmax_{x_1, \dots, x_K \in L} \sum_k t_k(x_k).
%% %% \]

%% Based on the motivation set out above, we present an iterative
%% strategy. Given a stochastic grammar $\mathcal{G}$ which defines a
%% distribution over the primitives from $\mathcal{L}$ and a integer
%% \emph{frontier size} $N$, we perform two steps in each iteration.  In
%% the first step, we explore the $N$ highest probability programs
%% according to $\mathcal{G}$. In the second step, we compress the
%% programs that solve any of our tasks, and we use that compression to
%% define a new grammar. Repeating these two steps, we effectively
%% reparameterize our search space to include programs that are more likely
%% to be solutions to our tasks. 

The remainder of this paper will include two major sections. In the
first, we describe in detail the EC algorithm and design choices we
make in implementing it. We will then present results from two
experiments in the domains of symbolic regression and Boolean
functioin learning.

%% \section{}
%% Let $\mathcal{F}$ be a family of distributions over $\mathcal{L}$ such
%% that for any $\mathcal{D} \in \mathcal{F}$ we can a) evaluate the
%% probability of program $p$, $P_D(p)$, and we can b) enumerate elements
%% from $D$ in descending order. 


%%  To motivate a solution to our problem, we begin with the hierarchical
%% Bayesian formulation of multi-task program induction found in Liang et
%% al.~\cite{liang10programs}. The general idea there is to estimate
%% solution programs for a set of related problems by inferring the posterior
%% distribution over solutions under the assumption that all the solution
%% programs are generated from a common latent stochastic grammar. By
%% jointly inferring solutions and the latent grammar, we find a set of
%% solutions that favors reuse of subcomponents.

%% While this framework is appealing in its elegance and Bayesian
%% interpretation, it cannot be straightforwardly adapted to the
%% situation we are considering here because their proposed MCMC
%% algorithm relies on a local log-likelihood signal, the very kind that
%% we are assuming we do not have access to.

%% To begin, we provide a high level overview of the algorithm and the
%% problem that it solves. The problem setup requires a representation
%% language for programs and a family of distributions over expressions
%% in that language, but we leave these details for the following section

\section{Extracting concepts from programs}

Our goal is to solve the following minimal feedback multi-task program
induction problem: suppose we are given a set of \textbf{tasks}
$T=\{t_k\}_{k=1}^K$ where each task is a function $t_k : \mathcal{L}
\rightarrow \{0, 1\}$ and where $\mathcal{L}$ is the set of
expressions in our language.  We say that expression $ e \in
\mathcal{L}$ \textbf{solves} $t_k$ if $ t_k(p) = 1$. Our goal is to
solve as many of the tasks in $T$ as we can.

We propose the \textbf{E-C algorithm}, an iterative procedure to solve this
problem. It will be useful in presenting the algorithm to define the
following terminology: a \textbf{frontier} is the finite set of
expressions that the algorithm considers in any one iteration. The
\textbf{frontier size} $N$ is the prespecified number of elements in
the frontier. We will say that a task is \textbf{hit} by the frontier
if there is a expression in the frontier that solves it.

The E-C algorithm maintains a distribution $\mathcal{D}$ over
expressions in $\mathcal{L}$. At each iteration, it
\begin{enumerate}
\item \textbf{explores} the frontier -- enumerating the $N$ most probable expressions
  from the current distribution $\mathcal{D}$ -- and
\item \textbf{compresses} the hit tasks in the frontier to estimate a new
  distribution.
\end{enumerate}

Next, we specify a representation language $\mathcal{L}$, a
form for the distribution $\mathcal{D}$, and a compression criterion for a
set of expressions in $\mathcal{L}$. We also describe
procedures for the enumeration of the frontier, compression of the
expressions, and re-estimation of $\mathcal{D}$. 

\subsection{Representing typed functional programs as binary trees}

Following~\cite{liang10programs} and~\cite{Briggs:2008}, we use a
simply typed combinatory logic -- a variable-free subset of the
polymorphic simply-typed lambda calculus~\cite{Pierce_2002} -- as our
program representation language. In short, the combinatory logic
introduces a \emph{basis} of several primitive \emph{combinators} such
that any function can be written as applications of the basis
combinators. Some common basis combinators are defined as follows:
\begin{align}
\mathbf{I}\; x &\rightarrow  x & \text{ (identity) }\\
\mathbf{S}\; f\; g\; x\; &\rightarrow (f\; x)\; (g\; x)\\ 
\mathbf{C}\; f\; g\; x\; &\rightarrow (f\; x)\; g  \\ 
\mathbf{B}\; f\; g\; x\; &\rightarrow f\; (g\; x) & \text{ (composition) }
\end{align}

The basis combinators are theoretically enough to express any Turing
computable function, but we will assume that our language has a
variety of primitives and, together with the basis combinators, we
call these the \textbf{primitive combinators}. Note that by default we consider
all primitives to be in their ``curried'' form (e.g. a function like
``+'' adds two numbers $x$ and $y$ by being first applied to $x$,
returning the function $(+\;x)$ and then being applied to $y$,
returning $(+\,x\,y)$\;).

The basis combinators can themselves be expressed in the lambda
calculus (with definitions following directly from the equations
above). The lambda calculus has two basic operations -- application
and abstraction (using the $\lambda$ operator -- but in using the
combinatory logic we sequester uses of the abstraction operation
inside the combinators. In doing so, we have replaced the variable
binding of the $\lambda$ operator with the variable \emph{routing} of
these basis combinators. Our representation thus becomes
variable-free. See Liang et al.~\cite{liang10programs} for a more
detailed discussion of this routing interpretation.

Using combinatory logic is very convenient for program
synthesis~\cite{briggs2006functional}: since every expression is the
application of one expression to another -- with this recursion
bottoming out at the primitive combinators -- each program is a binary
tree. Most importantly, any subtree is itself a well-formed
expression; this is not the case in the lambda calculus, since
abstraction introduces long range dependencies between the $\lambda$
operator and the variables to which that operator refers. In the
lambda calculus, then, a subtree might have free variables, not bound
to any enclosing $\lambda$.

As a simple example of our representation, consider the squaring
function $\lambda x. * x\; x $. Using two of the basis combinators
above, we can write the squaring function in combinatory logic as $S\; *\;
I$ (taking $*$ as a primitive), where application associates to the
left, so we drop the parentheses. When we apply this combinator to a
value $x$, the action of the combinator is defined as $S \;*\; I\;
x~\rightarrow~(*\; x)\; (I\; x)~\rightarrow *\; x \; x$.

We can extend this representation with a simple polymorphic type
system~\cite{Pierce_2002}. In this representation, a type is either a
type primitive (e.g. reals, integers, booleans, etc.), a type variable
(e.g. $\sigma$), or a function type $ \tau_1 \rightarrow \tau_2$ of
functions from source type $\tau_1$ to target type $\tau_2$. Any combinator
can be represented as a binary tree~(Figure~\ref{fig:clbintree}) whose
leaves are typed primitive combinators and whose interior nodes
represent typed applications of combinators (we annotate interior
nodes with their types).

\begin{figure}
%%  \centering
  \begin{subfigure}[Before]{0.45\linewidth}
    \begin{tikzpicture}[scale=.8,
        transform shape, level/.style={sibling distance=5mm/#1, font=\scriptsize}
        ]
      \node [font=\scriptsize] (top) {$\mathbb{R}$}
      child {node [above=.3cm, left=.1cm, text width=1.8cm] (a) {$(\mathbb{R} \rightarrow \mathbb{R}) \rightarrow \mathbb{R} 
          \rightarrow \mathbb{R}$}
        child {node [left=.5cm, below=1cm, text width=3.0cm] 
          {$ \mathbf{S} : (t_2 \rightarrow t_1 \rightarrow t_0)  \rightarrow (t_2 \rightarrow t_1) 
            \rightarrow \\ t_2 \rightarrow t_0$}}
        child {node [right=0cm, text width=2cm] {$ \mathbf{*}: \mathbb{R} \rightarrow \mathbb{R} \rightarrow \mathbb{R}$}}
      }
      child {node [below right=-.5cm and .2cm] (b) {$\mathbb{R} \rightarrow \mathbb{R}$}
        child {node [above=.5cm] {$ \mathbf{I}: t_0 \rightarrow t_0 \rightarrow t_0$}}
      }
    \end{tikzpicture}
    \caption{    \label{fig:clbintree}}
  \end{subfigure}
  \begin{subfigure}[After]{0.5\linewidth}
    \begin{tikzpicture}[scale=.7, transform shape, 
        level/.style={sibling distance=10mm/#1},
        every edge/.style={draw, thin}
      ]
      \node [circle,draw] (a) {}
      child {node [left=0cm] (b) {$f_1$}}
      child {node [left=.2cm] (c) {\dots} edge from parent[draw=none] }
      child {node [left=.4cm] (e) {$f_n$}}
      child {node [circle,draw, left=1cm] (d) {} edge from parent[very thick]
        child {node [circle, draw, left=.25cm] (l) {} edge from parent[draw=none]
          child {node [left=.5cm] (b) {$f_1$}} 
          child {node [left=.3cm] (c) {\dots} edge from parent[draw=none] }
          child {node [left=.3cm] (e) {$f_n$} edge from parent[very thick]}
          child {node [circle, draw, left=.25cm] (and2) {}
            child {node [circle, draw, left=.25cm](l2) {} edge from parent[draw=none] 
              child {node [above=.5cm] {\vdots} edge from parent[draw=none]}
            }
            child {node [circle, draw] (r2)  {} edge from parent[draw=none] 
              child {node [above=.5cm] {\vdots} edge from parent[draw=none]}
            }
          }
        }
        child {node [circle, draw, right=.25cm] (r) {} edge from parent[draw=none]
          child {node [circle, draw, right=.25cm] (and3) {}
            child {node [circle, draw ](l3) {} edge from parent[draw=none] 
              child {node [above=.5cm] {\vdots} edge from parent[draw=none]}
            }
            child {node [circle, draw, right=.2cm ] (r3)  {} edge from parent[draw=none] 
              child {node [above=.5cm] {\vdots} edge from parent[draw=none]}
            }
          }
          child {node [right=.3cm] (b) {$f_1$} edge from parent[very thick]} 
          child {node [right=.4cm] (c) {\dots} edge from parent[draw=none] }
          child {node [right=.6cm] (e) {$f_n$}}
        }
      };
      
      \path (d)  edge[very thick]  node[inner sep=0mm,pos=.4] (a1) {} node {} (l);
      \path (d)  edge[very thick]  node[inner sep=0mm,pos=.4] (b1) {} node {} (r);
      \path (a1) edge[bend right] (b1) ;

      \path (and2)  edge node[inner sep=0mm,pos=.4] (t0) {} node {} (l2);
      \path (and2)  edge node[inner sep=0mm,pos=.4] (k0) {} node {} (r2);
      \path (t0) edge[bend right] (k0) ;

      \path (and3)  edge node[inner sep=0mm,pos=.4] (t1) {} node {} (l3);
      \path (and3)  edge node[inner sep=0mm,pos=.4] (k1) {} node {} (r3);
      \path (t1) edge[bend right] (k1) ;
    \end{tikzpicture}
    \caption{  \label{fig:andor}}
    \end{subfigure}
  \caption{(a) The typed combinator $S * I$ ($f(x)=x^2$ over real values ($\mathbb{R}$)) represented as a
    binary tree. (b) The space of all typed combinators represented as an
    infinitely deep AND/OR tree.}

\end{figure}

\subsection{A stochastic grammar over programs}
\label{sec:stochgrammar}

We specify a distribution $\mathcal{D}$ over expressions in
$\mathcal{L}$ as a stochastic
grammar~\cite{feldman1969grammatical}. Many stochastic grammars have
the desirable property that the probability of an expression is the
product of the probabilities of its subcomponents. The distribution we
specify will be a simple verson of this, in which the
probability of an expression is the product of the probability of its
leaves.

Let ${C = c_1, \dots, c_N }$ be the primitive combinators in
$\mathcal{L}$. ${ \mathcal{D}=p_1, \dots, p_N }$ will associate with
each primitive combinator $c_i$ a prior probability $p_i$,
$0~\leq~p_i~\leq~1, \sum_i~p_i~=~1 $. The probability of a leaf with
primitive combinator $c_i$ will depend on which other primitive
combinators could have been chosen in its place. This set will depend
on the type that was requested by the parent of this leaf when the
leaf's primitive was chosen; we call this type the \emph{requesting}
type of the leaf. For example, suppose that we have the primitive
$(+1)$ of type $Int \rightarrow Int$ and the primitive $NOT$ of type
$Bool \rightarrow Bool$. If the requesting type is $\sigma \rightarrow
Int$, then we can only use $(+1)$, but if the requesting type is
$\sigma \rightarrow \sigma$ then we could use either $(+1)$ or
$NOT$. We define $C_\tau$ for any type $\tau$ to be the set of
primitive combinators in $C$ that are consistent with $\tau$, that is,
whose types \emph{unify} with $\tau$ (we use unification according to
the standard type theory presentation~\cite{Pierce_2002}).

Let $C_e$ be the set of primitive combinators in the leaves of
expressions $e$. We define the probability of an expression ${e \in
  \mathcal{L}}$ to be ${ p(e)~=~\prod_{c \in C_e} p(c | \tau(c)) }$
where $p(c | \tau(c))$ is the probability of using primitive $c$ when
the requesting type is $\tau(c)$. In turn, we define the conditional
probability for each combinator $c_n$ to be $p(c_n| \tau(c_n)) \propto
\frac{p}{\sum_{c_j \in C_{\tau(c_n)}} p_j}$.  That is, $p(c_n | \tau(c_n)$ is
proportional to the probability of sampling $c_n$ from the multinomial
distribution defined by the $p_n$'s, conditioned on the requesting
type, with the constant of proportionality chosen to ensure that the
sum over the probabilities of all expressions converges to a finite
value (so that the distribution over expressions is proper). For
binary trees, this is true whenever the constant of proportionality is
less than~$\frac{1}{4}$\footnote{The probability mass $M_d$ of all
  expressions of depth less than or equal to $d$ can be written with
  the recurrence relation $M_d \leq M_{d-1}^2 + M_1$. This has an
  asymptotic fixed point, as $d \rightarrow \infty$ if $x = x^2 + M_1$
  has a solution, which is true if $M_1~\leq~1/4$.}.

Now suppose that we have a set of expressions $\mathcal{E}$, and we
wish to estimate the maximum likelihood values of the $p_n$'s. If the
choice of primitive at each leaf were not conditioned on the
requesting type, we could just count all occurences of each primitive
in our expression set, and this would be proportional to the maximum
likelihood estimate. This is the ML estimator for a multinomial
distribution. However, the fact that we condition on the requesting
type makes this a considerably more difficult optimization task. One
of the simplest approximations we can make is to calculate the
frequency with which each primitive combinator appears in
$\mathcal{E}$ when the requesting type is such that it could have
been chosen. This is a straightforward calculuation, and
we use it for its convenience, finding that our empirical results
justify its use. Future inquiry will be needed to determine to what
extent a more accurate estimator can improve these results.

\subsection{Best-first enumeration of programs}
In order to explore the frontier of most promising programs, we need a
procedure that enumerates the $N$ most probable programs. There has
been recent interest in this problem, most of it focused on
enumerating the shortest program satisfying some
criterion~\cite{DBLP:conf/sfp/Katayama05}
\cite{DBLP:conf/aaip/YakushevJ09}. Our approach is to formulate the
problem as a best-first exploration of an AND/OR tree
(Figure~\ref{fig:andor})~\cite{nilsson1982principles}~\cite{DBLP:journals/cacm/Hall73}. In
words, the enumeration procedure is best described by the following
recursion: every program is either a primitive combinator or it is a
left child program applied to a right child program.

This can framed as the following AND/OR tree $\mathcal{G}$. Suppose we
want a program of type $\tau$. The root of $\mathcal{G}$ is an OR node of
type $\tau$. Its children are elements in $C_\tau$ (defined in the previous
section) and one AND node of type $\tau$ with two children. Each child of
an AND node has the same structure as the root node, with modified
types: the type of its left child is $\sigma \rightarrow \tau$ (where $\sigma$ is
a fresh type variable). Since the type of the right child is
constrained by the subtree rooted at the left child, we always expand
the left child first. Once we have a complete left child program, we
can use its target type as the type of the right child.

Recall that a valid partial solution $\mathcal{H}$ is a subtree of
$\mathcal{G}$ satisfying the following properties: the root of
$\mathcal{H}$ is the root of $\mathcal{G}$ and any OR node in
$\mathcal{H}$ has at most one child. $\mathcal{H}$ is a complete
solution (and thus a complete expression) if it is a partial solution
whose leaves are leaves of $\mathcal{G}$, if each OR node in
$\mathcal{H}$ has exactly one child, and if each AND node in
$\mathcal{H}$ is connected to all of that node's children in
$\mathcal{G}$

The value of a partial solution $\mathcal{H}$ is calculated by summing
the value of its leaves, where each such value is the log of the
probability assigned to that leaf in
Section~\ref{sec:stochgrammar}. If a leaf of $\mathcal{H}$ is a leaf
of $\mathcal{G}$ then either it is an AND node, to which we assign a
value of 0, or it corresponds to some primitive combinator $c_i$ in
the library and is the child of some typed OR node with type $t$. We
assign it a value of $\log{p(c_i | t)}$. If a leaf $v$ of
$\mathcal{H}$ is an OR node, then the value of any extension of it to
a complete solution is at most $log(1/4)$. Thus, we have defined a
value for partial solutions that upper bounds the value of any of its
extensions.

Our best-first policy is to expand the next partial solution
with the highest value. If a partial solution has multiple leaves that
are not primitive combinators, we expand the left most one first,
since it is the choice of left combinator that defines the type of its
right combinator in an application pair. That is, the parent node
applies its constraint on valid solutions via the left child, not the
right child. We want to apply constraints as early as possible, so
expanding left children first prunes more partial solutions.

\subsection{Finding the most compressive set of solutions}

Having enumerated the frontier, we want to assign solutions
to hit tasks such that this set is maximally compressible. This will
promote reusable modular subtrees. 

A natural metric for the compressibility of a set of binary trees is
the number of unique subtrees (counting leaves as subtrees) that this
set contains. As an example of this, suppose we had six tasks whose
solutions were integers $4^2, 5^2, 6^2, 7^2, 8^2$ and suppose our
frontier contained the 10 expressions:

\captionsetup[subfigure]{labelformat=empty} 
\begin{figure}[h!]
   \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.7, background rectangle/.style={fill=lightgray}] 
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[  * 4 ] 4 ]
     \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.7]
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[  * 5 ] 5 ]
     \end{tikzpicture}
  \end{subfigure}
   \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture} [scale=.7]
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[  * 6 ] 6 ]
     \end{tikzpicture}
  \end{subfigure}
   \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.7] 
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[  * 7 ] 7 ]
     \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.7] 
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[  * 8 ] 8 ]
     \end{tikzpicture}
  \end{subfigure}
  \vspace{2mm}

  \hdashrule{.9\linewidth}{1pt}{1pt}


  \vspace{2mm}
  \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.6] 
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[[  S * ] I ] 4 ]
     \end{tikzpicture}
     \caption{(16)}
  \end{subfigure}
  \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.6]
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[[  S * ] I ] 5 ]
     \end{tikzpicture}
     \caption{(25)}
  \end{subfigure}
   \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture} [scale=.6]
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[[  S * ] I ] 6 ]
     \end{tikzpicture}
     \caption{(36)}
  \end{subfigure}
  \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.6] 
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[[  S * ] I ] 7 ]
     \end{tikzpicture}
     \caption{(49)}
  \end{subfigure}
  \begin{subfigure}{.17\linewidth}
     \begin{tikzpicture}[scale=.6] 
       \tikzset{level distance=15pt, sibling distance=10pt}
       \Tree [[[  S * ] I ] 8 ]
     \end{tikzpicture}
     \caption{(64)}
  \end{subfigure}
\end{figure}
\captionsetup[subfigure]{labelformat=parens} 

The top row consists of one type of representation of an integer
squared, namely, the integer times itself. The bottom row contains
another type of representation in which the function $f(x)=x^2$,
represented in combinatory logic as $S * I$, is applied to the
integer. The top and bottom row of each expression evaluates to the
same integer. If we consider only the first column, the top tree has 4
unique subtrees and the bottom has 7. But each column adds 3 unique
subtrees to the top row and only 2 to the bottom. So by the fifth
column the top row has more unique subtrees than the bottom row. The
increased compressibility of the bottom row is due to the fact that
the squaring operation has been factored out as an abstraction. This
is an example of how this compressibility metric favors
abstraction when multiple expressions are being considered at once.

We want to choose a solution for each hit task such that the complete set
of such solutions for all solved tasks is as compressible as
possible. That is, let $t_i$ be a task in the set of hit tasks, and
let $\{e^k_i\}$ be the expressions in the frontier that solves
it. Then our goal is to find
\[
\{e^*_i\} = \argmin_{\{e^k_i\}} | \cup_i e^k_i |,
\]
where $|\cdot|$ denotes the number of unique trees in a set of expressions.

However, an exact optimization of this problem requires examining
$O(M^K)$ assignments, where $M$ is the maximum number of solutions for
any one task and $K$ is the number of tasks. Since this is
prohibitive, we relax the compressibility metric as follows: we define
the cost of adding each new solution $s_n$ to a partial set of
solutions $s_1, \dots, s_{n-1}$ to be the number of additional unique
subtrees in $s_n$ that are not present in $s_{n-1}$. That is, the
penalty of adding a new expression to the set of expressions depends
only on the last expression we added. Our solution thus becomes
approximate and that approximation is order-dependent, but a
depth-first search on the defined search space goes from exponential
in the solution degree to quadratic ($O(KM^2)$). 

However, when the number of solutions in the frontier grows, this
quadratic computation becomes prohibitive. Therefore, in practice, we
bound the number of potential expressions we are willing to consider
at any one iteration to any one task to a small number. We find that a
setting of this bound to 2 is computationally feasible and large
enough to guide subcomponent discovery in a reliable way. It may be
necessary to increase this bound as we scale this algorithm to larger
problems.

\subsection{Re-estimating the stochastic grammar}

Given a set of solution programs, we want to re-estimate our
stochastic grammar. Our inspiration for doing this is the
Neville-Manning algorithm for grammar-based
compression~\cite{nevill1997identifying}. The idea of that compression
algorithm is to compress any string by creating a grammar for that
string such that a) no two symbols appear more than once in the
grammar and b) every rule is used more than once. From a set of trees
we generate a grammar according to these criteria.

%% To do this, we traverse a set of combinator binary trees in
%% depth first order. We count the occurrences of every subtree. Every
%% time we encounter a subtree for the \emph{second} time, we designate
%% it as a primitive in our new grammar. This ensures that every
%% primitive is used more than once. During our traversal, we do not
%% descend into trees that have been added already to the new
%% grammar. Thus, we only count an instance of a tree if that instance is
%% not a subtree of a primitive element of the new grammar.

This procedure generates a parse of the solution set with a new set of
primitives, and we keep count of how many times each primitive
occurred in the solutions set. To estimate the probabilities
associated with each node production, we again traverse the solution
set, but this time for each node we count which other primitive
elements from the new grammar could have been used. In accordance with
Section~\ref{stochgrammar}, we estimate the terminal production weight
to be the ratio of the number of times that node was used in the first
traversal divided by the number of times it was used in the second
traversal.

\section{Experiments.}
\subsection{Symbolic regression.}
\label{sec:symreg}

We first illustrate the performance of our learning algorithm on a
symbolic regression problem. In task in this problem, we want to find
an algebraic function, symbolically specified, that maps a set of
input values to output values. We choose this problem because it has a
long history in AI, particularly in the genetic programming
literature~\cite{DBLP:books/daglib/0070933}. 

In the formulation we consider, each task $t$ corresponds to a
polynomial $f$, and an expression $e$ solves $t$ if ${ (e\; i)=f(i) }$
for all ${ i=0,\dots,9 }$. For this experiment, the set of problems
corresponds to the set of all polynomials with degree less than or
equal to 2. In the initial library, we include the basic combinators
I, S, B, C and four arithmetic primitives, $1$, $0$, $*$, and $+$. The
choice of initial weights on these primitives can make a difference,
as it determines the relative ordering of combinators in the
enumeration step. To get a general sense of the algorithm's
performance, we set the initial weights to be slightly different on
each run, perturbing them around a uniform weighting.

\setcounter{subfigure}{0} 
\begin{figure}[ht]
\centering
\begin{subfigure}[Before]{\linewidth}
\includegraphics[width=.9\linewidth]{figures/symreg3frontiers.pdf}
\caption{Learning curves as a function of frontier size.  As frontier
  size is increased, it plateaus closer to $100\%$ performance. A
  control brute-force search over $150000$ only hits $3\%$ of the
  tasks. \label{fig:symregLearning}}
\end{subfigure}

\begin{subfigure}[After]{\linewidth}
\includegraphics[width=.9\linewidth]{figures/symRegDiffCurricula.pdf}
\caption{How do different task sets affect learning curves? Learning
  curves at frontier size of $10000$ for different task
  sets. Performance is equally good if either the constant functions
  of the linear functions are missing, but drops dramatically when both
  are absent, even though these only account for about $10\%$ of the
  tasks. Performance drops even lower if we only consider ``complex''
  quadratics.}
\label{fig:symregCurricula}
\end{subfigure}
%% \begin{subfigure}[After]{.3\linewidth}\
%% \includegraphics[width=.9\linewidth]{figures/symregCircuitDepths.pdf}
%% \caption{Circuit depth as a function of iteration on a typical run.}
%% \label{fig:symregDepths}
%% \end{subfigure}
\vspace{-.2cm}
\caption{Symbolic regression experiment results.}
\label{fig:symreg} 
\end{figure}


%% Why do the learning curves asymptote early? One might object that a
%% learning algorithm should continuously improve, if only slowly, as it
%% is given more time. But in these runs we observe a finite and
%% permanent performance cap. This is expected: once the learner find a
%% set of concepts it can explain, if those concepts fill up the
%% frontier, then there is nothing to spur the learner to incorporate as
%% yet unsolved tasks. 

%% To investigate whether this is in fact the case, we can examine the
%% proportion of expressions in the frontier that match tasks in our task
%% set; that is, is the learning curve plateauing because the frontier is
%% heavily redundant, or is it plateuing because the frontier contains
%% many expressions that do not hit the task set at
%% all? Figure~\ref{fig:plateau_investigation} shows the proportion of
%% the expressions in the frontier that hit a task as the frontier size increases.


In Figure~\ref{fig:symregLearning}, we show performance results as we vary the
frontier size. Each individual plot shows how changing the frontier
size changes the number of tasks the algorithm identifies correctly
over the course of fifteen algorithm iterations. As a control, we
enumerated $10000*15=150000$ expressions from the initial
grammar. This is the total number of expressions that a run of the
algorithm sees if it has a frontier size of $10000$ and runs for $15$
iterations. Thus, if the benefit accruing to the runs with larger
frontier sizes is due to simple an increase in brute-force search
ability, rather than increased learning, we should see similarly good
performance from this control run. In fact, however, the control run
only hit $27$ of the $1000$ asks ($3\%$), whereas our algorithm nears $100\%$.

What kinds of primitives does the E-C algorithm learn in this task?
Inspecting the top weighted primitives of the final grammars, we find
many incrementers (e.g. (+1), (+2), etc.), several versions of
expressions that translate to functions like $x*f(x)$ and $f(x*f(x))$,
and combinations of these, like $x*(x+3)+3$ and $x*(x+2)$. Informally,
we see expressions that apply functions to themselves in various ways
several times, building up complex functions with relatively few
unique primitives. In the next experiment we will inspect more
directly the modular components that are learned by this algorithm.

We would like to assess to what degree ``conceptual bootstrapping'' is
responsible for the improved performance, that is, to what extent does
the presence of simple problems account for ability to learn complex
functions.  One prediction of this idea is that to succeed on a set of
tasks, the set must contain a ``learnable'' curriculum, a set of tasks
that serve as stepping stones from an impoverished representation to a
rich one. We can test this prediction by varying the set of tasks to
which the E-C algorithm is exposed.

In Figure~\ref{fig:symregCurricula}, we present learning curves
(frontier size 10000) corresponding to various versions of our
original symbolic regression task set. Recall that the original set
consisted of all polynomials of degree two or less and with
coefficients between 0 and 9. In the ``no constant'' task set, we
remove the 9 constant functions in this set. In the ``no linear'' task
set, we remove 90 linear functions from the set. We observe that
performance on those task sets does not decrease. However, when we
remove both the linear functions and the constant function (``only
quadratics''), we see a sharp drop in the algorithm's
performance. When we further restrict the task set to only ``complex''
quadratics (which we are defining as quadratics all of whose
coefficients are greater than zero), we observe another comparable
drop in performance. When we go one step further and restrict the task
set to quadratics with coefficients greater than 1, performance drops
to 0 because no task is hit in the initial frontier. 

This data has in it the nonlinearity that we predicted -- that a
minimal curriculum of simple tasks is sufficient to achieve high
performance -- but also suggests that, at least in this domain, this
is not an all-or-none effect. Though the performance drops
significantly once no linear functions are included in the task set,
learning does still occur, and the learning curves still have the same
basic shape. 

%% In addition, we have a
%% baseline for each curve, visits the same number of expressions as the
%% corresponding algorithm run (i.e. frontier size $\times$ $\#$ of
%% iterations) but all at once; it does not do any learning. Thus, this
%% baseline serves as a brute-force control for the learning aspect of
%% the algorithm.


\subsection{Boolean circuits}
\label{sec:boolcircuits}

\begin{figure}[ht]
\includegraphics{./tablealonedoc.pdf}
\vspace{-.5cm}
\caption{Some learned primitives in Boolean function learning
  experiment. We highlight compression using $NOT$, $E_1$ and $E_2$ in
  some of the expressions they are found. \,(a)The three elementary
  gates used to generate the task set. (b) Two higher-order primitives
  in the induced grammer. Note how $E_1$ can be used to define FALSE
  by taking the NOT function as an
  argument.  \label{table:booleanCircuits}}
\vspace{-.4cm}
\end{figure}



As another demonstration of this approach, we investigate the
procedure's ability to learn boolean functions using only the logical
primitive NAND and the basic combinators. It is well known that a
boolean circuit can be constructed for any boolean function given only
the NAND gate. Here, the basic combinators take the place of the
wiring normally found in a circuit, the output of element to multiple
inputs downstream. 


%% \begin{table}
%% \tiny
%% \begin{tabular}[width=\linewidth]{|p{1cm}|p{2cm}|p{3.5cm}|}
%% \hline function  & CL expression & circuit  ~ \\ \hline\hline
%% NOT & S NAND I &  ~

%% \begin{circuitikz}[transform shape]
%% \draw
%% (1.2,0) node[nand port, scale=.3] (nand1) {}
%% (0, 0) node (x) {x}
%% (x) -| (nand1.in 1)
%% (x) -| (nand1.in 2)
%% ;
%% \end{circuitikz}

%% \\ \hline
%% AND & ((C B NAND) (B (S NAND I))) & ~

%% \begin{circuitikz}
%% \draw
%% (1.0,0) node[nand port, scale=.3] (nand1) {}
%% (2.0,0) node[nand port, scale=.3] (nand2) {}
%% % (0, 0) node (x) {x}
%% % (0, 0) node (y) {y}
%% node[above left=.2cm and .7cm  of nand1] (x) {x} %-- (nand1.in 1)
%% node[below left=.2cm and .7cm  of nand1] (y) {y} %-- (nand1.in 2)
%% (x) |- (nand1.in 1)
%% (y) |- (nand1.in 2)
%% (nand1.out) |- (nand2.in 1)
%% (nand1.out) |- (nand2.in 2)
%% ;
%% \end{circuitikz}
%%  \\  \hline
%% OR & ((B (C (B (S NAND) NAND))) (S NAND I) & ~

%% \begin{circuitikz}
%% \draw
%% (0,0) node (x) {x}
%% (0,.7) node (y) {y}

%% node[nand port, scale=.3, right=1cm of x] (nand1) {}
%% node[nand port, scale=.3, right=1cm of y] (nand2) {}
%% node[nand port, scale=.3, below right=.3cm and 1cm of nand2] (nand3) {}
%% (x) -| (nand1.in 1)
%% (x) -| (nand1.in 2)
%% (y) -| (nand2.in 1)
%% (y) -| (nand2.in 2)
%% (nand1.out) |- (nand3.in 1)
%% (nand2.out) |- (nand3.in 2)
%% ;
%% \end{circuitikz}
%%  \\  \hline\hline

%% TRUE & (S NAND) (S NAND I) & ~ 

%% %\begin{top}
%% \begin{circuitikz}[transform shape] 
%% \draw
%% (1, 0) node[nand port, scale=.3] (nand1) {}
%% (2,.3) node[nand port, scale=.3] (nand2) {}
%% (0, 0) node[anchor=east]  (x) {x}
%% (x) -- (.3, 0) -| (nand1.in 1)
%% (x) -- (.3, 0) -|  (nand1.in 2)
%% (x) |- (nand2.in 1)
%% (nand1.out) |- (nand2.in 2)
%% ;
%% \end{circuitikz}
%% %\end{top}
%% \\ \hline
%% FALSE & (S B (S NAND)) (S NAND I) &  ~

%% \begin{circuitikz}[transform shape] 
%% \draw
%% (1, 0) node[nand port, scale=.3] (nand1) {}
%% (2,.3) node[nand port, scale=.3] (nand2) {}
%% node[nand port, scale=.3, right=1cm of nand2] (nand3) {} 
%% (0, 0) node[anchor=east]  (x) {x}
%% (x) -- (.3, 0) -| (nand1.in 1)
%% (x) -- (.3, 0) -|  (nand1.in 2)
%% (x) |- (nand2.in 1)
%% (nand1.out) |- (nand2.in 2)
%% (nand2.out) -| (nand3.in 1)
%% (nand2.out) -| (nand3.in 2)
%% ;
%% \end{circuitikz}
%% \\ \hline
%% XOR & ((S (B C (((B (C B NAND)) S) (((B (C B NAND)) S) (B C ((B (B NAND)) NAND)))))) I) & ~

%% \begin{circuitikz}
%% \draw
%% node[nand port, scale=.3] (nand1) {}
%% node[nand port, scale=.3, above right=.3cm and 1cm of nand1] (nand2) {} 
%% node[nand port, scale=.3, below right=.3cm and 1cm of nand1] (nand3) {} 
%% node[nand port, scale=.3, right=2cm of nand1] (nand4) {} 
%% node[left=1.2cm of nand2.in 1] (x) {x}
%% node[left=1.2cm of nand3.in 2] (y) {y}
%% node[right=.2cm of nand4] (out) {}
%% (x) -| (nand1.in 1)
%% (x) -| (nand2.in 1)
%% (y) -| (nand1.in 2)
%% (y) -| (nand3.in 2)
%% (nand1.out) -| (nand2.in 2)
%% (nand1.out) -| (nand3.in 1)
%% (nand2.out) |- (nand4.in 1)
%% (nand3.out) |- (nand4.in 2)
%% (nand4.out) -- (out)
%% ;
%% \end{circuitikz}

%%  \\  \hline\hline
%% $E_1$  & S B (S NAND) & ~

%% \begin{circuitikz}
%% \draw
%% node (x) {x}
%% node[nand port, scale=.3, right=1.5cm of x] (nand) {} 
%% node[draw=blue!75, fill=blue!20, thick, 
%%   above right=.3cm and .2cm of x, anchor=west] (f1) {$g(x)$} 
%% node[draw=blue!75, fill=blue!20, thick, right=.5cm of nand] (f2) {$g(x)$}
%% node[right=.1cm of f2] (out) {}
%% (x) -| (f1.west)
%% (x) -| (nand.in 2)
%% (f1) -| (nand.in 1)
%% (nand.out) -- (f2)
%% (f2) -- (out);
%% \end{circuitikz}

%% \\ \hline
%% $E_2$  & B (C B NAND) S & ~

%% \begin{circuitikz}
%% \draw
%% node (x) {x} 
%% node[nand port, scale=.3, right=1.5cm of x] (nand) {} 
%% node[draw=blue!75, fill=blue!20, thick, 
%%   above right=.2cm and .3cm of x, anchor=west] (g) {$g(x)$} 
%% node[draw=blue!75, fill=blue!20, thick, 
%%   below right=.2cm and .3cm of x, anchor=west] (f) {$f(x)$} 
%% (x) -- [right=.25] (f.west)
%% (x) |- (g.west)
%% (f.east) -| (nand.in 1)
%% (g.east) -| (nand.in 2)
%% (nand.out) -- (out)
%% (x)
%% ;
%% \end{circuitikz}

%% \\ \hline

%% \end{tabular}
%% \caption{Expressions in the induced library on sets of tasks
%%   corresponding to boolean circuits synthesized from AND, OR, and NOT
%%   gates, with boolean circuits of 1, 2, or 3 inputs.}
%% \label{table:boolexpr}

%% \end{table}


%% \begin{table}[t]
%% \scriptsize
%%    \begin{tabular}{|l|l|l|}
%%     function  & CL expressions & circuit  ~ \\ \hline
%% TRUE & (S NAND) (S NAND I) & ~ \\ \hline
%% FALSE & (S B (S NAND)) (S NAND I) & ~ \\ \hline
%% NOT & S NAND I & \input{figures/NOT.tex} \\ \hline
%% AND & ((C B NAND) (B (S NAND I))) & ~ \\ 
%% OR & ((B (C (B (S NAND) NAND))) (S NAND I) & ~ \\ 
%% XOR & ~ & ~ \\ 
%% F  & S B (S NAND) & \input{figures/F.tex}
%% \end{tabular}
%% \end{table}



We constructed two task sets. The first of these was constructed
explicitly to contain familiar module structure. In this set of tasks,
we sampled $1000$ boolean circuits using AND, OR, and NOT gates. To
accomplish this, we first sampled either 1, 2, 3 inputs, then between
1 and 5 gates, randomly wiring the inputs of each new gate to the
output of one of the existing gates in the circuit. We continued this
sampling procedure until we had 1000 ``connected'' circuits, i.e.,
circuits all of whose output are wired to an input except for the last
one (the output gate). This resulted in $1000$ tasks consisting of
$82$ unique boolean functions, with a distribution of tasks as shown
in Figure~\ref{fig:booldistr}. In Figure~\ref{fig:boolLearningCurvesCircuits},
We present learning curves for frontier sizes 100, 500 and 10000,
using the same procedure as in Section~\ref{sec:symreg}. 


\begin{figure}
\vspace{-.3cm}
\includegraphics[width=\linewidth]{figures/circuitDistrComp.pdf}
\vspace{-.6cm}
\caption{Distribution of boolean functions among (a) the set of 1000
  circuits randomly constructed from AND, OR and NOT gates (see text);
  b) the first 1000 expressions from the grammar over programs
  \emph{before} learning; c) the first 1000 expressions from the
  grammar over programs \emph{after} learning. Gray levels indicate
  percent of instances (circuits/expressions) which evaluate to that
  function.\label{fig:booldistr}}
\end{figure}

This problem is particularly suitable for inspecting the constituents
of the induced grammar $\mathcal{G}$. We might hope that our algorithm
recovers the constituent logic gates that were used to build up the
problems. Table~\ref{table:bool} shows a few of the top ranked
expressions in the library. These include the basic logic gates; we
also include one higher-order expression $F$, to stress that the
representation we are using allows one to build concepts that are more
expressive that just sub-circuits.

In a second experiment, we include all $272$ boolean truth tables with
three or fewer inputs as tasks. This is a more difficult problem. Note
that in the first boolean function problem, there are two kinds of
learning that can take place: first, many expressions map to a single
boolean function, so we need to learn primitives that allow us to span
many different functions instead of allows generating very simple
functions over and over again. The second kind of learning involves
the distribution of the functions themselves. In the first boolean
experiment, that structure is apparent in the distribution in
Figure~\ref{fig:boolhist}. In this second experiment, we remove the
second kind of structure. In Figure~\ref{fig:boolLearningCurvesUniform}, we show
10 runs of the algorithm with a frontier size of $2000$: note how
there are several local minima that majority of the runs get stuck in
with performance around $50\%$, but several of the runs seem to take
different trajectories to more successful representations. 

\begin{figure}[h]
\begin{subfigure}{.1\linewidth}
\caption{\label{fig:boolLearningCurvesCircuits} }
\end{subfigure}
\begin{subfigure}[Before]{.9\linewidth}
\includegraphics[width=.9\linewidth]{figures/booleancircuits3frontiers.pdf}
\end{subfigure}

\vspace{-.2cm}
\begin{subfigure}{.1\linewidth}
\caption{\label{fig:boolLearningCurvesUnifrom}}
\end{subfigure}
\begin{subfigure}[After]{.9\linewidth}
\includegraphics[width=.9\linewidth]{figures/booleanfunctionsUniform.pdf}

\end{subfigure}
\vspace{-.3cm}
\caption{Learning curves from Boolean function learning
  experiment. (a) Learning curves for various frontier sizes on task
  set of Boolean functions drawn randomly from a distribution (see
  text for details) of circuits built up of NOT, AND, OR gates. (b) 10
  learning curves for frontier size of 2000 on a task set consisting
  of all Boolean functions of cardinality 3 or smaller. Note how most
  of the trajectories get stuck in a local minimum around
  $50\%$.\label{fig:boolLearningCurves}

}
\vspace{-.5cm}
\end{figure}

%% \subsection{Digital arithmetic}
%% Having demonstrated the behavior of the E-C algorithm on symbolic
%% regression, we analyze its performance on tasks involving digital
%% arithmetic, a class of problems with known modular structure. The
%% general goal is to discover boolean circuits consisting of a limited
%% set of gates that perform arithmetic operations on binary number
%% representations. 


\section{Discussion}
This work attempts to bring together ideas from various areas of
research -- hierarchical Bayes, learning to learn, minimum description
length learning -- to provide a proof of concept that learning
abstractions from programs via compression can rapidly improve search
performance. We emphasize this by focusing on domains in which the
solution space is not smooth and the error signal is all or
none. Thus, the main source of information for learning is the modular
and compositional structure of the solution space.

Of course, the representations that people use to learn in the world
often have a partially smooth or local structure. Techniques in AI and
machine learning commonly use smoothness or local structure to make
search tractable. But the difference between this kind of learning and
conceptual learning is undeniable. The former is what the statistician
or machine learning researcher implements. The latter is what she
learns as a student and as a practicioner. As researchers, we try
different models, watch them fail or succeed, and abstract out the
elements of these models that capture the relevant differences. We mix
and match parts of different ideas, and utilize succcessful patterns
of reasoning that can span many problems and domains. 

We believe that the primary characteristic of conceptual learning is
that it occurs over a modular and compositional computational
representation that supports higher-order functions. That is why we
chose a functional programming language as the representational
language of this work.

The experiments in this work do not contain the richness of real world
learning, but we believe that the learning algorithm's behavior
exhibits some of the characteristics we would expect of a conceptual
learner. 

One characteristic of this algorithm's behavior is a rapid initial
increase in performance followed by a hard plateau. This plateau is
expected given the circular nature of the algorithm: the learner
inspects the region of the solution space that is typical of solutions
already found. We see in this phenomenon a conceptual demarcation of
the problem space: a coherent set of concepts or problems solving
techniques can define by their power the extent of problems a problem
solver is willing to consider. One might hope, however, that an
intelligent learner would recognize that such a demarcation has
occured and attempt to find another class of concepts for the
remaining unsolved tasks.

Another aspect of conceptual learning that we see present in this
algorithm's behavior is the importance of a curriculum. By this we do
not mean an explicit ordering of the problems in the task set, but
rather that a set of sufficiently simple problems must act as stepping
stones to the acquisition of complex representations. 




%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{plain}
\bibliography{ijcai13}
%% \nocite{*}

\end{document}

